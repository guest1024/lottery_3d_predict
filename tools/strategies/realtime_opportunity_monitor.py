"""
å®æ—¶æœºä¼šç›‘æ§ç³»ç»Ÿ
================

åŠŸèƒ½ï¼š
1. å®æ—¶è®¡ç®—æœ€æ–°ä¸€æœŸçš„æœºä¼šè¯„åˆ†
2. åˆ¤æ–­æ˜¯å¦è¾¾åˆ°æŠ•æ³¨é˜ˆå€¼
3. å¦‚æœè¾¾åˆ°é˜ˆå€¼ï¼Œç”ŸæˆæŠ•æ³¨å»ºè®®
4. è¾“å‡ºè¯¦ç»†çš„ç‰¹å¾åˆ†æå’ŒæŠ•æ³¨è®¡åˆ’
"""

import json
import numpy as np
import torch
from pathlib import Path
from collections import Counter
from typing import List, Dict
import sys
from datetime import datetime

sys.path.insert(0, '/c1/program/lottery_3d_predict')
from src.models.lottery_model import LotteryModel

PRIZE_CONFIG = {
    'direct': 1040,
    'group3': 346,
    'group6': 173,
}
TICKET_PRICE = 2

# è¯„åˆ†é˜ˆå€¼ï¼ˆåŸºäºå†å²å›æµ‹ï¼‰
SCORE_THRESHOLDS = {
    'top1': 58.45,   # Top1% - ROI 405%, èƒœç‡67%
    'top5': 57.17,   # Top5% - ROI -57%, èƒœç‡20%
    'top10': 56.90,  # Top10% - ROI -13%, èƒœç‡17%
}

# æ¨èç­–ç•¥
RECOMMENDED_STRATEGY = 'top1'
RECOMMENDED_THRESHOLD = SCORE_THRESHOLDS['top1']


class OpportunityScorer:
    """æœºä¼šè¯„åˆ†ç³»ç»Ÿ"""
    
    FEATURE_WEIGHTS = {
        'top1_prob': 15,
        'top3_mean_prob': 15,
        'gap_1_2': 10,
        'prob_std': 10,
        'top3_concentration': 10,
        'digit_freq_std': 8,
        'shape_entropy': 7,
        'sum_std': 5,
        'recent_5_unique_count': 5,
        'max_consecutive_shape': 5,
    }
    
    @staticmethod
    def calculate_score_with_details(digit_probs: np.ndarray, history: np.ndarray) -> Dict:
        """è®¡ç®—è¯„åˆ†å¹¶è¿”å›è¯¦ç»†ç‰¹å¾"""
        # æ¨¡å‹ç‰¹å¾
        sorted_indices = np.argsort(digit_probs)[::-1]
        sorted_probs = digit_probs[sorted_indices]
        
        top1_prob = sorted_probs[0]
        top3_mean_prob = np.mean(sorted_probs[:3])
        gap_1_2 = sorted_probs[0] - sorted_probs[1] if len(sorted_probs) > 1 else 0
        prob_std = np.std(digit_probs)
        top3_concentration = np.sum(sorted_probs[:3]) / (np.sum(digit_probs) + 1e-10)
        
        # åºåˆ—ç‰¹å¾
        flat_history = history.flatten()
        digit_counts = Counter(flat_history)
        digit_freq_std = np.std(list(digit_counts.values()))
        
        shape_counts = Counter()
        for numbers in history:
            shape = OpportunityScorer._get_shape(numbers)
            shape_counts[shape] += 1
        shape_entropy = OpportunityScorer._calculate_entropy(shape_counts)
        
        sum_values = [np.sum(numbers) for numbers in history]
        sum_std = np.std(sum_values)
        
        recent_5 = history[-5:]
        recent_5_unique_count = len(set(map(tuple, recent_5)))
        
        shapes = [OpportunityScorer._get_shape(numbers) for numbers in history]
        max_consecutive_shape = OpportunityScorer._max_consecutive(shapes)
        
        # åŸå§‹ç‰¹å¾å€¼
        raw_features = {
            'top1_prob': top1_prob,
            'top3_mean_prob': top3_mean_prob,
            'gap_1_2': gap_1_2,
            'prob_std': prob_std,
            'top3_concentration': top3_concentration,
            'digit_freq_std': digit_freq_std,
            'shape_entropy': shape_entropy,
            'sum_std': sum_std,
            'recent_5_unique_count': recent_5_unique_count,
            'max_consecutive_shape': max_consecutive_shape,
        }
        
        # å½’ä¸€åŒ–ç‰¹å¾
        normalized_features = {
            'top1_prob': min(1.0, top1_prob / 0.3),
            'top3_mean_prob': min(1.0, top3_mean_prob / 0.3),
            'gap_1_2': min(1.0, gap_1_2 / 0.1),
            'prob_std': min(1.0, prob_std / 0.3),
            'top3_concentration': min(1.0, top3_concentration),
            'digit_freq_std': min(1.0, digit_freq_std / 5.0),
            'shape_entropy': min(1.0, shape_entropy),
            'sum_std': min(1.0, sum_std / 5.0),
            'recent_5_unique_count': min(1.0, recent_5_unique_count / 5.0),
            'max_consecutive_shape': min(1.0, max_consecutive_shape / 10.0),
        }
        
        # è®¡ç®—å„ç‰¹å¾è´¡çŒ®åˆ†æ•°
        feature_contributions = {
            k: normalized_features[k] * OpportunityScorer.FEATURE_WEIGHTS[k]
            for k in normalized_features.keys()
        }
        
        # æ€»åˆ†
        total_score = sum(feature_contributions.values())
        
        return {
            'total_score': float(total_score),
            'raw_features': raw_features,
            'normalized_features': normalized_features,
            'feature_contributions': feature_contributions,
            'feature_weights': OpportunityScorer.FEATURE_WEIGHTS,
        }
    
    @staticmethod
    def _get_shape(numbers: np.ndarray) -> str:
        counter = Counter(numbers)
        if len(counter) == 1:
            return 'leopard'
        elif len(counter) == 2:
            return 'group3'
        else:
            return 'group6'
    
    @staticmethod
    def _calculate_entropy(counter: Counter) -> float:
        total = sum(counter.values())
        if total == 0:
            return 0
        probs = [count / total for count in counter.values()]
        return -sum(p * np.log(p + 1e-10) for p in probs)
    
    @staticmethod
    def _max_consecutive(sequence: List) -> int:
        if not sequence:
            return 0
        max_count = 1
        current_count = 1
        for i in range(1, len(sequence)):
            if sequence[i] == sequence[i-1]:
                current_count += 1
                max_count = max(max_count, current_count)
            else:
                current_count = 1
        return max_count


def generate_bets(top_digits: List[int], score: float, num_bets_base: int = 50) -> List[tuple]:
    """ç”ŸæˆæŠ•æ³¨ç»„åˆ"""
    if score >= SCORE_THRESHOLDS['top1']:
        num_bets = int(num_bets_base * 1.5)  # 75æ³¨
    else:
        num_bets = num_bets_base
    
    bets = set()
    
    # ç»„å…­ï¼ˆ70%ï¼‰
    group6_count = int(num_bets * 0.7)
    attempts = 0
    while len([b for b in bets if len(set(b)) == 3]) < group6_count and attempts < group6_count * 3:
        combo = tuple(sorted(np.random.choice(top_digits, size=3, replace=False)))
        if len(set(combo)) == 3:
            bets.add(combo)
        attempts += 1
    
    # ç»„ä¸‰ï¼ˆ30%ï¼‰
    group3_count = num_bets - len(bets)
    attempts = 0
    while len(bets) < num_bets and attempts < group3_count * 3:
        digit1 = np.random.choice(top_digits)
        digit2 = np.random.choice([d for d in top_digits if d != digit1])
        combo = tuple(sorted([digit1, digit1, digit2]))
        bets.add(combo)
        attempts += 1
    
    return list(bets)[:num_bets]


def monitor_current_opportunity():
    """ç›‘æ§å½“å‰æœºä¼š"""
    print("="*80)
    print("ğŸ¯ å®æ—¶æœºä¼šç›‘æ§ç³»ç»Ÿ")
    print("="*80)
    print(f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ¨èç­–ç•¥: Top1%æåº¦ä¿å®ˆç­–ç•¥")
    print(f"æŠ•æ³¨é˜ˆå€¼: {RECOMMENDED_THRESHOLD:.2f}åˆ†")
    print("="*80)
    
    # åŠ è½½æ•°æ®
    print("\n[1] åŠ è½½æ•°æ®å’Œæ¨¡å‹...")
    data_file = 'data/lottery_3d_real_20260205_125506.json'
    with open(data_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    all_data = data['data']
    
    # æœ€æ–°30æœŸä½œä¸ºè¾“å…¥
    recent_30 = all_data[-30:]
    sequences = np.array([item['numbers'] for item in recent_30])
    
    # ä¸Šä¸€æœŸå¼€å¥–ç»“æœ
    last_period = all_data[-1]
    
    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ")
    print(f"  æœ€æ–°ä¸€æœŸ: {last_period['period']}")
    print(f"  å¼€å¥–æ—¥æœŸ: {last_period['date']}")
    print(f"  å¼€å¥–å·ç : {last_period['numbers']}")
    
    # åŠ è½½æ¨¡å‹
    device = torch.device('cpu')
    model = LotteryModel.load('models/checkpoints/best_model.pth', device=device)
    print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # é¢„æµ‹ä¸‹ä¸€æœŸ
    print(f"\n[2] é¢„æµ‹ä¸‹ä¸€æœŸ...")
    model.eval()
    with torch.no_grad():
        input_seq = torch.LongTensor(sequences).unsqueeze(0).to(device)
        predictions = model.predict(input_seq)
        digit_probs = predictions['digit_probs'][0]
    
    # è®¡ç®—æœºä¼šè¯„åˆ†
    print(f"\n[3] è®¡ç®—æœºä¼šè¯„åˆ†...")
    scorer = OpportunityScorer()
    score_details = scorer.calculate_score_with_details(digit_probs, sequences)
    
    total_score = score_details['total_score']
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š æœºä¼šè¯„åˆ†: {total_score:.2f}åˆ†")
    print(f"{'='*80}")
    
    # é˜ˆå€¼å¯¹æ¯”
    print(f"\né˜ˆå€¼å¯¹æ¯”:")
    for strategy_name, threshold in SCORE_THRESHOLDS.items():
        status = "âœ… è¾¾åˆ°" if total_score >= threshold else "âŒ æœªè¾¾åˆ°"
        print(f"  {strategy_name.upper():<6} (é˜ˆå€¼{threshold:.2f}): {status}")
    
    # ç‰¹å¾è¯¦æƒ…
    print(f"\n[4] ç‰¹å¾è¯¦æƒ…åˆ†æ:")
    print(f"\n{'ç‰¹å¾åç§°':<25} {'åŸå§‹å€¼':<12} {'å½’ä¸€åŒ–':<12} {'æƒé‡':<8} {'è´¡çŒ®åˆ†':<10}")
    print("-"*80)
    
    for feat_name in score_details['feature_contributions'].keys():
        raw_val = score_details['raw_features'][feat_name]
        norm_val = score_details['normalized_features'][feat_name]
        weight = score_details['feature_weights'][feat_name]
        contrib = score_details['feature_contributions'][feat_name]
        
        print(f"{feat_name:<25} {raw_val:<12.4f} {norm_val:<12.4f} {weight:<8} {contrib:<10.2f}")
    
    print(f"\næ€»åˆ†: {total_score:.2f}")
    
    # Topæ•°å­—
    top_indices = np.argsort(digit_probs)[::-1]
    top10_digits = top_indices[:10].tolist()
    top10_probs = digit_probs[top_indices[:10]]
    
    print(f"\n[5] Top10é¢„æµ‹æ•°å­—:")
    print(f"{'æ’å':<6} {'æ•°å­—':<6} {'æ¦‚ç‡':<10}")
    print("-"*30)
    for i, (digit, prob) in enumerate(zip(top10_digits, top10_probs), 1):
        print(f"{i:<6} {digit:<6} {prob:<10.4f}")
    
    # æŠ•æ³¨å»ºè®®
    print(f"\n{'='*80}")
    print(f"ğŸ° æŠ•æ³¨å»ºè®®")
    print(f"{'='*80}")
    
    if total_score >= RECOMMENDED_THRESHOLD:
        print(f"\nâœ… å½“å‰è¯„åˆ† {total_score:.2f} â‰¥ æ¨èé˜ˆå€¼ {RECOMMENDED_THRESHOLD:.2f}")
        print(f"âœ… å»ºè®®è¿›è¡ŒæŠ•æ³¨ï¼")
        
        # ç”ŸæˆæŠ•æ³¨ç»„åˆ
        bet_combos = generate_bets(top10_digits, total_score, num_bets_base=50)
        total_cost = len(bet_combos) * TICKET_PRICE
        
        print(f"\næŠ•æ³¨è®¡åˆ’:")
        print(f"  æŠ•æ³¨æ•°é‡: {len(bet_combos)}æ³¨")
        print(f"  æ€»æˆæœ¬: Â¥{total_cost}")
        print(f"  åŸºäºå†å²å›æµ‹:")
        print(f"    - é¢„æœŸèƒœç‡: 66.67%")
        print(f"    - é¢„æœŸROI: 405.42%")
        print(f"    - é¢„æœŸæ”¶ç›Š: Â¥{total_cost * 4.05:.0f}")
        
        # åˆ†ç±»ç»Ÿè®¡
        group6_bets = [b for b in bet_combos if len(set(b)) == 3]
        group3_bets = [b for b in bet_combos if len(set(b)) == 2]
        
        print(f"\næŠ•æ³¨ç»„åˆåˆ†ç±»:")
        print(f"  ç»„å…­: {len(group6_bets)}æ³¨ (æ¯æ³¨ä¸­å¥–Â¥173)")
        print(f"  ç»„ä¸‰: {len(group3_bets)}æ³¨ (æ¯æ³¨ä¸­å¥–Â¥346)")
        
        print(f"\nå‰30æ³¨æ¨è:")
        for i, combo in enumerate(bet_combos[:30], 1):
            combo_type = "ç»„å…­" if len(set(combo)) == 3 else "ç»„ä¸‰"
            print(f"  {i:2d}. {combo[0]} {combo[1]} {combo[2]} ({combo_type})")
        
        if len(bet_combos) > 30:
            print(f"  ... (å…±{len(bet_combos)}æ³¨)")
        
        # ä¿å­˜æŠ•æ³¨è®¡åˆ’
        output = {
            'timestamp': datetime.now().isoformat(),
            'last_period': {
                'period': last_period['period'],
                'date': last_period['date'],
                'numbers': last_period['numbers'],
            },
            'opportunity_score': total_score,
            'threshold': RECOMMENDED_THRESHOLD,
            'recommendation': 'BET',
            'betting_plan': {
                'num_bets': len(bet_combos),
                'total_cost': total_cost,
                'combinations': [[int(x) for x in combo] for combo in bet_combos],
                'expected_win_rate': 0.6667,
                'expected_roi': 4.0542,
            },
            'score_details': {
                'total_score': total_score,
                'feature_contributions': {
                    k: float(v) for k, v in score_details['feature_contributions'].items()
                },
            },
            'top10_digits': [int(d) for d in top10_digits],
            'top10_probs': [float(p) for p in top10_probs],
        }
        
        output_path = Path('results/current_opportunity.json')
        output_path.parent.mkdir(exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ“ æŠ•æ³¨è®¡åˆ’å·²ä¿å­˜åˆ°: {output_path}")
        
    else:
        print(f"\nâŒ å½“å‰è¯„åˆ† {total_score:.2f} < æ¨èé˜ˆå€¼ {RECOMMENDED_THRESHOLD:.2f}")
        print(f"âŒ ä¸å»ºè®®æŠ•æ³¨ï¼Œç»§ç»­è§‚æœ›")
        print(f"\nè¯„åˆ†å·®è·: {RECOMMENDED_THRESHOLD - total_score:.2f}åˆ†")
        print(f"\nå»ºè®®: ç­‰å¾…è¯„åˆ†â‰¥{RECOMMENDED_THRESHOLD:.2f}æ—¶å†å…¥åœº")
        
        # ä¿å­˜è§‚æœ›è®°å½•
        output = {
            'timestamp': datetime.now().isoformat(),
            'last_period': {
                'period': last_period['period'],
                'date': last_period['date'],
                'numbers': last_period['numbers'],
            },
            'opportunity_score': total_score,
            'threshold': RECOMMENDED_THRESHOLD,
            'recommendation': 'SKIP',
            'score_gap': RECOMMENDED_THRESHOLD - total_score,
            'top10_digits': [int(d) for d in top10_digits],
        }
        
        output_path = Path('results/current_opportunity.json')
        output_path.parent.mkdir(exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ“ è§‚æœ›è®°å½•å·²ä¿å­˜åˆ°: {output_path}")
    
    print(f"\n{'='*80}")
    print(f"âš ï¸  æŠ•èµ„é£é™©æç¤º")
    print(f"{'='*80}")
    print(f"â€¢ å½©ç¥¨æ˜¯æ¦‚ç‡æ¸¸æˆï¼Œå†å²ä¸šç»©ä¸ä»£è¡¨æœªæ¥è¡¨ç°")
    print(f"â€¢ å³ä½¿Top1%ç­–ç•¥å†å²èƒœç‡67%ï¼Œä»æœ‰33%æ¦‚ç‡äºæŸ")
    print(f"â€¢ å»ºè®®å•æ¬¡æŠ•æ³¨é‡‘é¢â‰¤æ€»èµ„é‡‘çš„5%")
    print(f"â€¢ ç†æ€§è´­å½©ï¼Œå¨±ä¹ä¸ºä¸»")
    print(f"{'='*80}\n")


if __name__ == '__main__':
    monitor_current_opportunity()
