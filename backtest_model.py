"""
å›æµ‹æ¨¡å‹åœ¨å†å²æ•°æ®ä¸Šçš„å‡†ç¡®ç‡
ä½¿ç”¨æ»‘åŠ¨çª—å£æ–¹å¼è¿›è¡Œwalk-forwardå›æµ‹
"""
import sys
sys.path.insert(0, '/c1/program/lottery_3d_predict')

import json
import numpy as np
import torch
from collections import defaultdict
from pathlib import Path

from src.models.lottery_model import LotteryModel

def load_data(json_file, num_records=1200):
    """åŠ è½½æ•°æ®"""
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    recent_data = data['data'][-num_records:]
    sequences = np.array([item['numbers'] for item in recent_data])
    return sequences, recent_data

def predict_single(model, history_30, device='cpu'):
    """
    é¢„æµ‹å•æœŸå·ç 
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        history_30: æœ€è¿‘30æœŸå†å²æ•°æ® (30, 3)
        
    Returns:
        é¢„æµ‹çš„æ•°å­—æ¦‚ç‡åˆ†å¸ƒå’ŒTopé¢„æµ‹
    """
    input_seq = torch.LongTensor(history_30).unsqueeze(0).to(device)
    
    model.eval()
    with torch.no_grad():
        predictions = model.predict(input_seq)
        digit_probs = predictions['digit_probs'][0]
        
        # Top 5é¢„æµ‹
        top5_digits = np.argsort(digit_probs)[-5:][::-1]
        
        return {
            'digit_probs': digit_probs,
            'top5': top5_digits,
            'top3': top5_digits[:3],
            'top1': top5_digits[0]
        }

def evaluate_prediction(pred, actual):
    """
    è¯„ä¼°å•æ¬¡é¢„æµ‹
    
    Args:
        pred: é¢„æµ‹ç»“æœ
        actual: å®é™…å·ç  [d0, d1, d2]
        
    Returns:
        è¯„ä¼°æŒ‡æ ‡
    """
    metrics = {
        'exact_match': False,
        'position_match': [False, False, False],
        'any_digit_match': False,
        'top5_hit_count': 0,
        'top3_hit_count': 0,
        'top1_hit': False
    }
    
    # å®Œå…¨åŒ¹é…
    if np.array_equal(pred['top1'], actual):
        metrics['exact_match'] = True
    
    # ä½ç½®åŒ¹é… (æ£€æŸ¥Top5ä¸­æ˜¯å¦åŒ…å«è¯¥ä½ç½®çš„æ•°å­—)
    for i, digit in enumerate(actual):
        if digit in pred['top5']:
            metrics['position_match'][i] = True
    
    # ä»»æ„æ•°å­—å‘½ä¸­
    actual_set = set(actual)
    top5_set = set(pred['top5'])
    if actual_set & top5_set:
        metrics['any_digit_match'] = True
    
    # Top5å‘½ä¸­æ•°
    metrics['top5_hit_count'] = len(actual_set & top5_set)
    
    # Top3å‘½ä¸­æ•°
    top3_set = set(pred['top3'])
    metrics['top3_hit_count'] = len(actual_set & top3_set)
    
    # Top1å‘½ä¸­
    if pred['top1'] in actual_set:
        metrics['top1_hit'] = True
    
    return metrics

def backtest_rolling(sequences, raw_data, model, window_size=30, test_periods=200, device='cpu'):
    """
    æ»šåŠ¨çª—å£å›æµ‹
    
    Args:
        sequences: æ‰€æœ‰å†å²æ•°æ®
        raw_data: åŸå§‹æ•°æ®(åŒ…å«æœŸå·)
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        window_size: å†å²çª—å£å¤§å°
        test_periods: å›æµ‹æœŸæ•°
        
    Returns:
        å›æµ‹ç»“æœç»Ÿè®¡
    """
    print(f"\nå¼€å§‹æ»šåŠ¨çª—å£å›æµ‹...")
    print(f"  çª—å£å¤§å°: {window_size}")
    print(f"  å›æµ‹æœŸæ•°: {test_periods}")
    
    results = []
    aggregate_metrics = defaultdict(int)
    
    # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
    total_available = len(sequences) - window_size
    test_periods = min(test_periods, total_available)
    
    start_idx = len(sequences) - test_periods - window_size
    
    for i in range(test_periods):
        idx = start_idx + i
        
        # è·å–å†å²30æœŸ
        history = sequences[idx:idx + window_size]
        
        # å®é™…å·ç 
        actual = sequences[idx + window_size]
        actual_period = raw_data[idx + window_size]['period']
        
        # é¢„æµ‹
        pred = predict_single(model, history, device)
        
        # è¯„ä¼°
        metrics = evaluate_prediction(pred, actual)
        
        # è®°å½•ç»“æœ
        result = {
            'period': actual_period,
            'actual': actual.tolist(),
            'predicted_top5': pred['top5'].tolist(),
            'predicted_top3': pred['top3'].tolist(),
            'predicted_top1': int(pred['top1']),
            'metrics': metrics
        }
        results.append(result)
        
        # ç´¯è®¡ç»Ÿè®¡
        aggregate_metrics['total'] += 1
        aggregate_metrics['exact_match'] += int(metrics['exact_match'])
        aggregate_metrics['any_digit_match'] += int(metrics['any_digit_match'])
        aggregate_metrics['top1_hit'] += int(metrics['top1_hit'])
        
        for pos in range(3):
            aggregate_metrics[f'position_{pos}_match'] += int(metrics['position_match'][pos])
        
        aggregate_metrics['top5_hit_total'] += metrics['top5_hit_count']
        aggregate_metrics['top3_hit_total'] += metrics['top3_hit_count']
        
        # è¿›åº¦æ˜¾ç¤º
        if (i + 1) % 50 == 0:
            print(f"  è¿›åº¦: {i+1}/{test_periods} ({(i+1)/test_periods*100:.1f}%)")
    
    print(f"  å®Œæˆ: {test_periods}/{test_periods} (100.0%)")
    
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    n = aggregate_metrics['total']
    statistics = {
        'total_predictions': n,
        'exact_match_rate': aggregate_metrics['exact_match'] / n,
        'any_digit_match_rate': aggregate_metrics['any_digit_match'] / n,
        'top1_hit_rate': aggregate_metrics['top1_hit'] / n,
        'position_0_match_rate': aggregate_metrics['position_0_match'] / n,
        'position_1_match_rate': aggregate_metrics['position_1_match'] / n,
        'position_2_match_rate': aggregate_metrics['position_2_match'] / n,
        'avg_position_match_rate': (
            aggregate_metrics['position_0_match'] +
            aggregate_metrics['position_1_match'] +
            aggregate_metrics['position_2_match']
        ) / (n * 3),
        'avg_top5_hits': aggregate_metrics['top5_hit_total'] / n,
        'avg_top3_hits': aggregate_metrics['top3_hit_total'] / n,
    }
    
    return results, statistics

def analyze_by_time_period(results):
    """æŒ‰æ—¶é—´æ®µåˆ†æå‡†ç¡®ç‡"""
    # åˆ†æ®µç»Ÿè®¡
    segment_size = 50
    segments = []
    
    for i in range(0, len(results), segment_size):
        segment = results[i:i + segment_size]
        
        stats = {
            'start_period': segment[0]['period'],
            'end_period': segment[-1]['period'],
            'count': len(segment),
            'top1_hit_rate': sum(r['metrics']['top1_hit'] for r in segment) / len(segment),
            'avg_position_match': sum(
                sum(r['metrics']['position_match']) for r in segment
            ) / (len(segment) * 3),
            'any_digit_match_rate': sum(r['metrics']['any_digit_match'] for r in segment) / len(segment)
        }
        
        segments.append(stats)
    
    return segments

def analyze_by_digit_frequency(results, sequences):
    """åˆ†æä¸åŒæ•°å­—çš„é¢„æµ‹å‡†ç¡®ç‡"""
    digit_stats = defaultdict(lambda: {'predicted': 0, 'actual': 0, 'hit': 0})
    
    for result in results:
        actual_set = set(result['actual'])
        top5_set = set(result['predicted_top5'])
        
        # ç»Ÿè®¡é¢„æµ‹
        for d in top5_set:
            digit_stats[d]['predicted'] += 1
            if d in actual_set:
                digit_stats[d]['hit'] += 1
        
        # ç»Ÿè®¡å®é™…
        for d in actual_set:
            digit_stats[d]['actual'] += 1
    
    # è®¡ç®—å‡†ç¡®ç‡
    digit_analysis = {}
    for digit in range(10):
        stats = digit_stats[digit]
        digit_analysis[digit] = {
            'predicted_count': stats['predicted'],
            'actual_count': stats['actual'],
            'hit_count': stats['hit'],
            'precision': stats['hit'] / stats['predicted'] if stats['predicted'] > 0 else 0,
            'recall': stats['hit'] / stats['actual'] if stats['actual'] > 0 else 0
        }
    
    return digit_analysis

def main():
    print("=" * 80)
    print("3Då½©ç¥¨é¢„æµ‹æ¨¡å‹å›æµ‹ç³»ç»Ÿ")
    print("=" * 80)
    
    device = torch.device('cpu')
    
    # 1. åŠ è½½æ•°æ®å’Œæ¨¡å‹
    print(f"\n[1] åŠ è½½æ•°æ®å’Œæ¨¡å‹")
    data_file = 'data/lottery_3d_real_20260205_125506.json'
    sequences, raw_data = load_data(data_file, num_records=1200)
    
    model = LotteryModel.load('models/checkpoints/best_model.pth', device=device)
    
    print(f"âœ“ æ•°æ®èŒƒå›´: {raw_data[0]['period']} åˆ° {raw_data[-1]['period']}")
    print(f"âœ“ æ€»è®°å½•æ•°: {len(sequences)}")
    print(f"âœ“ æ¨¡å‹å·²åŠ è½½")
    
    # 2. æ‰§è¡Œå›æµ‹
    print(f"\n[2] æ‰§è¡Œæ»šåŠ¨çª—å£å›æµ‹")
    results, statistics = backtest_rolling(
        sequences=sequences,
        raw_data=raw_data,
        model=model,
        window_size=30,
        test_periods=200,  # å›æµ‹æœ€è¿‘200æœŸ
        device=device
    )
    
    # 3. æ˜¾ç¤ºæ•´ä½“ç»Ÿè®¡
    print(f"\n[3] æ•´ä½“å›æµ‹ç»Ÿè®¡")
    print(f"\n{'='*60}")
    print(f"æ€»ä½“æ€§èƒ½æŒ‡æ ‡ (å›æµ‹{statistics['total_predictions']}æœŸ)")
    print(f"{'='*60}")
    
    print(f"\næ ¸å¿ƒæŒ‡æ ‡:")
    print(f"  å¹³å‡ä½ç½®åŒ¹é…ç‡: {statistics['avg_position_match_rate']:.2%}")
    print(f"    - ä½ç½®0åŒ¹é…ç‡: {statistics['position_0_match_rate']:.2%}")
    print(f"    - ä½ç½®1åŒ¹é…ç‡: {statistics['position_1_match_rate']:.2%}")
    print(f"    - ä½ç½®2åŒ¹é…ç‡: {statistics['position_2_match_rate']:.2%}")
    
    print(f"\nTopé¢„æµ‹æ€§èƒ½:")
    print(f"  Top1å‘½ä¸­ç‡: {statistics['top1_hit_rate']:.2%}")
    print(f"  Top3å¹³å‡å‘½ä¸­æ•°: {statistics['avg_top3_hits']:.2f}/3")
    print(f"  Top5å¹³å‡å‘½ä¸­æ•°: {statistics['avg_top5_hits']:.2f}/3")
    print(f"  ä»»æ„æ•°å­—å‘½ä¸­ç‡: {statistics['any_digit_match_rate']:.2%}")
    
    print(f"\nå®Œå…¨åŒ¹é…:")
    print(f"  å®Œå…¨åŒ¹é…ç‡: {statistics['exact_match_rate']:.2%}")
    
    # 4. æ—¶é—´æ®µåˆ†æ
    print(f"\n[4] æ—¶é—´æ®µè¡¨ç°åˆ†æ")
    segments = analyze_by_time_period(results)
    
    print(f"\næ¯50æœŸç»Ÿè®¡:")
    print(f"{'æ—¶é—´æ®µ':<30} | {'Top1å‘½ä¸­':<10} | {'ä½ç½®åŒ¹é…':<10} | {'ä»»æ„å‘½ä¸­':<10}")
    print(f"{'-'*70}")
    for seg in segments:
        period_range = f"{seg['start_period'][:10]} ~ {seg['end_period'][:10]}"
        print(f"{period_range:<30} | "
              f"{seg['top1_hit_rate']:>8.1%}  | "
              f"{seg['avg_position_match']:>8.1%}  | "
              f"{seg['any_digit_match_rate']:>8.1%}")
    
    # 5. æ•°å­—çº§åˆ«åˆ†æ
    print(f"\n[5] å„æ•°å­—é¢„æµ‹è¡¨ç°")
    digit_analysis = analyze_by_digit_frequency(results, sequences)
    
    print(f"\n{'æ•°å­—':<6} | {'é¢„æµ‹æ¬¡æ•°':<10} | {'å®é™…æ¬¡æ•°':<10} | {'å‘½ä¸­æ¬¡æ•°':<10} | {'ç²¾ç¡®ç‡':<10} | {'å¬å›ç‡':<10}")
    print(f"{'-'*75}")
    for digit in range(10):
        stats = digit_analysis[digit]
        print(f"{digit:<6} | "
              f"{stats['predicted_count']:>8}  | "
              f"{stats['actual_count']:>8}  | "
              f"{stats['hit_count']:>8}  | "
              f"{stats['precision']:>8.1%}  | "
              f"{stats['recall']:>8.1%}")
    
    # 6. æœ€è¿‘10æœŸè¯¦ç»†ç»“æœ
    print(f"\n[6] æœ€è¿‘10æœŸé¢„æµ‹è¯¦æƒ…")
    print(f"\n{'æœŸå·':<15} | {'å®é™…å·ç ':<12} | {'Top5é¢„æµ‹':<20} | {'å‘½ä¸­æƒ…å†µ':<15}")
    print(f"{'-'*70}")
    for result in results[-10:]:
        actual_str = ' '.join(map(str, result['actual']))
        top5_str = ' '.join(map(str, result['predicted_top5']))
        
        # æ ‡è®°å‘½ä¸­
        hit_marks = []
        actual_set = set(result['actual'])
        for d in result['predicted_top5']:
            hit_marks.append('âœ“' if d in actual_set else 'âœ—')
        hit_str = ' '.join(hit_marks)
        
        print(f"{result['period']:<15} | "
              f"{actual_str:<12} | "
              f"{top5_str:<20} | "
              f"{hit_str:<15}")
    
    # 7. ä¿å­˜å›æµ‹ç»“æœ
    print(f"\n[7] ä¿å­˜å›æµ‹ç»“æœ")
    
    backtest_report = {
        'summary': {
            'total_predictions': statistics['total_predictions'],
            'data_range': {
                'start': raw_data[-statistics['total_predictions']]['period'],
                'end': raw_data[-1]['period']
            },
            'overall_statistics': {
                'avg_position_match_rate': float(statistics['avg_position_match_rate']),
                'position_0_match_rate': float(statistics['position_0_match_rate']),
                'position_1_match_rate': float(statistics['position_1_match_rate']),
                'position_2_match_rate': float(statistics['position_2_match_rate']),
                'top1_hit_rate': float(statistics['top1_hit_rate']),
                'top3_avg_hits': float(statistics['avg_top3_hits']),
                'top5_avg_hits': float(statistics['avg_top5_hits']),
                'any_digit_match_rate': float(statistics['any_digit_match_rate']),
                'exact_match_rate': float(statistics['exact_match_rate'])
            }
        },
        'time_segments': [
            {
                'start_period': seg['start_period'],
                'end_period': seg['end_period'],
                'count': seg['count'],
                'top1_hit_rate': float(seg['top1_hit_rate']),
                'avg_position_match': float(seg['avg_position_match']),
                'any_digit_match_rate': float(seg['any_digit_match_rate'])
            }
            for seg in segments
        ],
        'digit_analysis': {
            str(d): {
                'predicted_count': stats['predicted_count'],
                'actual_count': stats['actual_count'],
                'hit_count': stats['hit_count'],
                'precision': float(stats['precision']),
                'recall': float(stats['recall'])
            }
            for d, stats in digit_analysis.items()
        },
        'recent_10_predictions': [
            {
                'period': r['period'],
                'actual': r['actual'],
                'predicted_top5': r['predicted_top5'],
                'predicted_top3': r['predicted_top3'],
                'top5_hit_count': r['metrics']['top5_hit_count'],
                'position_match': r['metrics']['position_match']
            }
            for r in results[-10:]
        ]
    }
    
    output_file = 'results/backtest_results.json'
    Path('results').mkdir(exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(backtest_report, f, ensure_ascii=False, indent=2)
    
    print(f"âœ“ å›æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # 8. æ€§èƒ½æ€»ç»“
    print(f"\n{'='*80}")
    print("å›æµ‹æ€§èƒ½æ€»ç»“")
    print(f"{'='*80}")
    
    print(f"\nâœ… ä¼˜åŠ¿:")
    if statistics['avg_position_match_rate'] > 0.25:
        print(f"  - ä½ç½®åŒ¹é…ç‡{statistics['avg_position_match_rate']:.1%}æ˜¾è‘—é«˜äºéšæœºæ°´å¹³(10%)")
    if statistics['avg_top5_hits'] > 1.0:
        print(f"  - Top5å¹³å‡å‘½ä¸­{statistics['avg_top5_hits']:.2f}ä¸ªæ•°å­—,è¡¨ç°è‰¯å¥½")
    if statistics['any_digit_match_rate'] > 0.80:
        print(f"  - {statistics['any_digit_match_rate']:.1%}çš„æœŸæ•°è‡³å°‘å‘½ä¸­ä¸€ä¸ªæ•°å­—")
    
    print(f"\nâš ï¸  å±€é™:")
    if statistics['exact_match_rate'] < 0.01:
        print(f"  - å®Œå…¨åŒ¹é…ç‡{statistics['exact_match_rate']:.2%},ç²¾ç¡®é¢„æµ‹ä»ç„¶æå…¶å›°éš¾")
    if statistics['top1_hit_rate'] < 0.40:
        print(f"  - Top1å‘½ä¸­ç‡{statistics['top1_hit_rate']:.1%},å•ä¸€é¢„æµ‹å‡†ç¡®æ€§æœ‰é™")
    
    print(f"\nğŸ’¡ å»ºè®®:")
    print(f"  - ä½¿ç”¨Top5é¢„æµ‹ä½œä¸ºå€™é€‰æ± ,è€Œéå•ä¸€å·ç ")
    print(f"  - ç»“åˆå†å²ç»Ÿè®¡å’Œæ¨¡å‹é¢„æµ‹ç»¼åˆå†³ç­–")
    print(f"  - æ¨¡å‹é€‚åˆè¾…åŠ©åˆ†æ,ä¸èƒ½ä¿è¯ç›ˆåˆ©")
    print(f"  - ç†æ€§è´­å½©,å¨±ä¹ä¸ºä¸»")
    
    print("\n" + "=" * 80)
    print("å›æµ‹å®Œæˆ!")
    print("=" * 80)

if __name__ == '__main__':
    main()
